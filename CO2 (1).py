# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uL1u0Ddz0mA0vmmy82Na0WsRArsqaK0Q
"""

import pandas as pd
import numpy as np
import sklearn
import seaborn as sns
import matplotlib.pyplot as plt

data=pd.read_csv("co2.csv")
data

data.shape

data.describe()

sns.displot(data['out1'],kind='kde')

data.isnull().sum()

X=data.drop('out1',axis=1)
X

y=data["out1"]
y

correlation=data.corr()
correlation

sns.heatmap(correlation,annot=True,cmap="Blues")

"""corr between our features and target values are close to 1 so there are linear relationship between them and we can use this for model selection"""

#Train test split
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)

X_train.shape

X_test.shape

#model selection
from sklearn.linear_model import LinearRegression
model=LinearRegression()
#fit our model
model.fit(X_train,y_train)
y_pred=model.predict(X_test)

y_pred

from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score
mae=mean_absolute_error(y_pred,y_test)
mse=mean_squared_error(y_pred,y_test)
r2=r2_score(y_pred,y_test)
print("model MSE is:",mse)
print("model mean_absolute_error is:",mae)
print("model R_squared_error is:",r2)

scores=model.score(X_train,y_train)
scores

Scores=model.score(X_test,y_pred)
Scores

#our model is overfit because test score is greater than train set
from sklearn import svm
clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)
y2_pred=clf.predict(X_test)
y2_pred

Scores=model.score(X_test,y2_pred)
Scores

"""SVm is better model for this dataset without cross validation"""

from sklearn.model_selection import ShuffleSplit
from sklearn.model_selection import cross_val_score
cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)
scores=cross_val_score(clf, X_train, y_train, cv=cv)
scores